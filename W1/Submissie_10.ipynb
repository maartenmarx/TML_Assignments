{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Applied Machine Learning BSc IK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "privacy",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Notebook made by\n",
    "\n",
    "**Gebruik graag dit formaat**\n",
    "\n",
    "* Voor de namen:  voornaam rest van je naam, voornaam rest van je naam,....\n",
    "* je studentnummers: hetzelfde: scheidt met `,`\n",
    "* je emails: hetzelfde: scheidt met `,`\n",
    "* voor je groep: **alleen de hoofdletter** (iets als  `A` of `B` dus)\n",
    "\n",
    "__Namen__:Anoniem",
    "\n",
    "__Emails__:Anoniem",
    "\n",
    "__Student id__:Anoniem",
    "\n",
    "__Groep__:Anoniem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toelichting\n",
    "\n",
    "* Een aantal opgaven worden automatisch nagekeken. Bij vrijwel alle opdrachten staan er een paar tests onder de opdracht, dit is voornamelijk om te zorgen dat je de juiste type output geeft. Dit zijn dus *NIET* alle tests, die komen er bij het graden nog bij.\n",
    "* Elke vraag is 1 punt waard, tenzij anders aangegeven. Soms is die punt onderverdeeld in deelpunten, maar niet altijd. \n",
    "\n",
    "## Voor het inleveren!\n",
    "\n",
    "* Pas niet de cellen aan, vooral niet die je niet kunt editen. Dit levert problemen op bij nakijken. Twijfel je of je per ongeluk iets hebt gewijzigd, kopieer dan bij inleveren je antwoorden naar een nieuw bestand, zodat het niet fout kan gaan.\n",
    "\n",
    "* Zorg dat de code goed runt van boven naar beneden, verifieer dat door boven in Kernel -> Restart & Run All uit te voeren\n",
    "\n",
    "## Na het inleveren!\n",
    "\n",
    "* Het gebeurt erg vaak dat mensen een \"leeg bestand\" inleveren. Vaak een andere versie van de opgave die nog ergens op je computer rondslingerde. Zonde van al je werk toch!\n",
    "* Dus, lever **minstens een half uur voor tijd in**. Download dan wat je hebt ingeleverd op Canvas. Geef het een andere naam om verwarring te voorkomen. En draai alle cellen, en bekijk het. Geen syntax fouten? Alle vragen gemaakt? Dan zit het vast wel goed, en hoef je niet in de zenuwen te zitten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "X-yY70P1pnS6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82da87da8f1a450d81fbfa15e951a3fb",
     "grade": false,
     "grade_id": "cell-575272ac8c88383d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Applied Machine Learning W1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 5685,
     "status": "ok",
     "timestamp": 1618341657662,
     "user": {
      "displayName": "Bob De witte",
      "photoUrl": "",
      "userId": "14788410831395393646"
     },
     "user_tz": -60
    },
    "id": "OwtzrP7-z4LS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b01a49de3dc95c799fd399f591e1560",
     "grade": false,
     "grade_id": "nose",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "2790d9c4-f682-4b96-ac6b-a023ed9c24b3"
   },
   "outputs": [],
   "source": [
    "!pip install nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vkP8dRV-pnTI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62a2753f522c0a9a7758c77b31a99bfd",
     "grade": false,
     "grade_id": "cell-f55bc95980e83e55",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from scipy.stats import mode\n",
    "from nose.tools import assert_count_equal, assert_equal\n",
    "from numpy.testing import *\n",
    "from pandas.testing import assert_frame_equal\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import datasets\n",
    "# Please do not remove this: \n",
    "np.random.seed(31415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7a566395bf9dd24fe39c3be9f2147da",
     "grade": false,
     "grade_id": "th",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Theory\n",
    "\n",
    "With these questions you and your group will practice your ability to formulate key concepts precisely and short. \n",
    "Such questions  also appear in the exams, and are graded quite strict.\n",
    "\n",
    "Always answer in one grammatically correct English sentence. \n",
    "\n",
    "Finish the following sentences:\n",
    "\n",
    "1. Machine learning algorithms build a model ...\n",
    "2. Machine learning can be divided into three parts, namely .....\n",
    "3. Each of these 3 parts can be described as follows:\n",
    "    1. .... is ....\n",
    "    1. .... is ....\n",
    "    1. .... is ....\n",
    "4. The key difference between regression and classification problems is .....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb5562762f320d9dec1038b28fed2176",
     "grade": true,
     "grade_id": "tha",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "1. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions on new unseen data, without being explicitly programmed to do so.\n",
    "2. Machine learning can be divided into three parts, namely supervised, unsupervised and reinforcement learning.\n",
    "3. Each of these 3 parts can be described as follows:\n",
    "4. The key difference between regression and classification problems is dat je bij een classificatie een item wilt voorspellen/ toebehoren aan een groep/categorie en dat je een item bij regressie wilt laten toebehoren/voorspellen aan een getal/cijfer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0b3e89ab2b281827b55efe339240f4c",
     "grade": false,
     "grade_id": "part0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part 0 classification with the iris data set, using knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95c0a4249298206ebd0cba6abc6c5ea5",
     "grade": false,
     "grade_id": "iris1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "iris= datasets.load_iris()\n",
    "\n",
    "X,y= iris.data, iris.target\n",
    "print(X.shape,y.shape)\n",
    "print(X[:5])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f93c750d6d7382c56acc9cb2a977c791",
     "grade": false,
     "grade_id": "irist",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# train test\n",
    "\n",
    "Use `np.random.choice` to create random `X_train, X_test, y_train, y_test`  such that \n",
    "\n",
    "1. 90 train, 60 test\n",
    "2. Stratified, so an equal amount of cases from each of the three classes in the train and test sets.\n",
    "\n",
    "Make tests to test that what you create is according to these specs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3e4d8062c0db1f8336ed6e965cbc28c",
     "grade": false,
     "grade_id": "irist2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Note about our questions, and how to answer them\n",
    "\n",
    "Here and later we may ask you to program things explicitly, and thus **not** using a scikit learn or other routine. Please do so, and practice this. We will do the same in the exam. It is important that you understand the algorithms behind the concepts that you use. That is the reason. Also we believe that you understand and remember things better when you have programmed than from scratch.\n",
    "\n",
    "Of course you can google the answer in a few minutes and copy-paste it. But does that give your satisfaction or gratification? Do you *learn* anything from it? Please do not work like that. You make these assignments with 4 students, so you really have a lot of time. Make them all, compare and discuss the 4 found solutions, improve and refactor  them to one super great siolution. And, if all this does not appeal to you, then maybe this does: at the exam we will also ask these questions, and you do not have access to the web then. \n",
    "\n",
    "### making tests\n",
    "\n",
    "This is an underdeveloped skill with many students. Why? Testing your own answer gives you a good feeling, it often lets you improve your answer, and can also be seen as a way to find the (complete) answer. **Please practice it and take it seriously.** At the exam you will have a notebook too, and so you can also test your own answers. Being skillfull in testing will boost your grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d9214d57d3f80fa47e1f863d90d11e6",
     "grade": false,
     "grade_id": "iristta",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test,  y_test =[],[],[],[] # replace by your answer\n",
    "\n",
    "# Beginning \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4 , stratify=y\n",
    "    \n",
    ")\n",
    "\n",
    "# End solution\n",
    "for M in [X_train, y_train, X_test,  y_test]:\n",
    "    print( M.shape)\n",
    "print(y_test)\n",
    "# print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c47b149939e1b35b9d228cdd8261d655",
     "grade": true,
     "grade_id": "ttt",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(X_train.shape,(90, 4))\n",
    "assert_equal(X_test.shape,(60, 4))\n",
    "assert_equal(y_train.shape,(90, ))\n",
    "assert_equal(y_test.shape,(60, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee1cc257a29270dfdeef56dc36409c6c",
     "grade": false,
     "grade_id": "irisknn",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# knn classifier\n",
    "\n",
    "Program from scratch a knn classifier which can work on data `X` and `y` as you have from the iris dataset.\n",
    "\n",
    "It returns the most common label in the k nearest neighbors.\n",
    "\n",
    "### Hints\n",
    "\n",
    "* use `euclidean` as your distance function\n",
    "* `X_train[0,:]` picks out the first instance from `X_train`.\n",
    "* Use *fancy indexing* to take out a number of items from a numpy array. as in `X[8,35,7,2]`.\n",
    "* `np.argsort` is handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4899914940bf4e13d8e67d1cffa8eb05",
     "grade": false,
     "grade_id": "irisknna",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def knn(X,y,example,k=5):\n",
    "    '''Classify example using majority vote of the k closest items in X with labels y.'''\n",
    "    #WRITE YOUR CODE HERE\n",
    "    dist = np.argsort([euclidean(example, i)for i in X])[:k]\n",
    "    kNN_Y = [y[i] for i in dist]\n",
    "    return mode(kNN_Y)[0][0]\n",
    "\n",
    "\n",
    "[ knn(X_train,y_train,i) for i in X_test[:10]]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7732a4dbcc13b407d4433925303d56bd",
     "grade": false,
     "grade_id": "irisknneval",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "Run knn on `X_test` and compare the outcomes to `y_test`.\n",
    "\n",
    "Come up with a useful and insightfull error report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88b56402886d501f49390e16ff14a301",
     "grade": true,
     "grade_id": "irisevala",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "print('accuracy' , (np.array(y_test) == np.array(y_pred)).mean())\n",
    "\n",
    "y_pred = [knn(X_train, y_train,i) for i in X_test]\n",
    "\n",
    "for l in (0,1,2):\n",
    "    Xl,yl= X_test[y_test==l], y_test[y_test==l]\n",
    "    yl_pred= [ knn(X_train,y_train,i) for i in X1]\n",
    "    errors= [i for i in yl_pred if i!=1]\n",
    "    print('accuracy for label',str(1),'is', (np.array(y1)==np.array(y1_pred)).mean(),'. Errors are ', errors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d15b8d8310c1607b74afe76460f3c867",
     "grade": false,
     "grade_id": "heap",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Make more efficient\n",
    "\n",
    "1. Estimate what work is done when running knn on one new to be classified instance, given that it has $n$ training examples. \n",
    "2. How expensive is the sorting step?\n",
    "3. Remove the sorting step by programming a heap of size $k$ which contains from the train set already inspected  the $k$ closest instances to the unseen example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b27a47198787d76eba2ed04b2a539238",
     "grade": true,
     "grade_id": "heapa",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fe618e1da226dba611e2de33f0840e9",
     "grade": false,
     "grade_id": "heapa2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def knn_heap(X,y,example,k=5):\n",
    "    '''Classify example using majority vote of the k closest items in X with labels y.'''\n",
    "    # Begin solution \n",
    "    return mode(kNN_Y)[0][0]\n",
    "\n",
    "\n",
    "[ knn(X_train,y_train,i) for i in X_test[:10]] \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tYWhz0bxdZo9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e627ff51f2f552cdd88f90e02ed61ee0",
     "grade": false,
     "grade_id": "cell-8452bfe549fa98ac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Predicting a value with knn-regression\n",
    "\n",
    "## Part 1: Loading the data into a Pandas Data Frame  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_X5Vt2jMpnTX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a6c69ccd90e8b7155025f7f0bea2857",
     "grade": false,
     "grade_id": "1a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The descriptions of the columns of the dataset can be found here:\n",
    "\n",
    "**pop**: population\n",
    "\n",
    "**pctUrban**: percentage of people living in areas classified as urban\n",
    "\n",
    "**medIncome**: Median Income\n",
    "\n",
    "**pct12-29**: percentage of population that is 12-21 in age\n",
    "\n",
    "**pct65up**: percentage of population that is 65 and over in age\n",
    "\n",
    "**pctPoverty**: percentage of people under the poverty level\n",
    "\n",
    "**pctAllDivorc**: percentage of population who are divorced\n",
    "\n",
    "**pctUnemploy**: percentage of people 16 and over, in the labor force, and unemployed\n",
    "\n",
    "**perHoush**: mean persons per household\n",
    "\n",
    "**pctHousOccup**: percent of housing occupied\n",
    "\n",
    "**persHomeless**: number of homeless people\n",
    "\n",
    "**persEmergShelt**: number of people in homeless shelters\n",
    "\n",
    "**nonViolPerPop**: total number of non-violent crimes per 100K popuation\n",
    "\n",
    "**State**: the state in which this town/city is located\n",
    "\n",
    "**countyCode**: the code number of the county of the state this town/city is located\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "l2kUe2uupnTY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bedb86a7b8388cd494485a4bb7bec32a",
     "grade": false,
     "grade_id": "1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "\n",
    "### Question 1a:\n",
    "Load the data into a Pandas DataFrame. At this point, make sure that you only load the following columns: \n",
    "\n",
    "`'pop', 'pctUrban', 'medIncome', 'pct12-29', 'pct65up', 'pctPoverty', 'pctAllDivorc', 'pctUnemploy', 'perHoush', 'pctHousOccup', 'persHomeless', 'persEmergShelt', 'nonViolPerPop'`\n",
    "\n",
    "\n",
    "Here and elsewhere, when we load data, always use the `loadfile()` command. Like in `pd.read_csv(loadfile())`. We do this because when we (auto)grade we have the file not in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TZbYd5WvpnTZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d05763fb1d92ed6640b9caa11d0eb5fe",
     "grade": false,
     "grade_id": "1c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def loadfile():\n",
    "    if 'crime_data.csv.gz' in os.listdir():\n",
    "        return 'crime_data.csv.gz'\n",
    "    elif os.path.exists('../../data/Week1/'):\n",
    "        return '../../data/Week1/crime_data.csv.gz'\n",
    "    elif os.path.exists('../../../data/Week1/'):\n",
    "        return '../../../data/Week1/crime_data.csv.gz'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'crime_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 6740,
     "status": "error",
     "timestamp": 1618341658738,
     "user": {
      "displayName": "Bob De witte",
      "photoUrl": "",
      "userId": "14788410831395393646"
     },
     "user_tz": -60
    },
    "id": "Nucu0E17pnTk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc6eb752aec729b90b42a928b39dc8c1",
     "grade": false,
     "grade_id": "cell-9a5813b911a397d1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "cfa384cb-56ca-4d18-c2be-6f3cb64bfe43",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "crime_data = pd.read_csv(loadfile(),sep=\",\",compression='gzip', header = 0,\n",
    "                 usecols=['pop', 'pctUrban', 'medIncome', 'pct12-29', 'pct65up', 'pctPoverty', 'pctAllDivorc', 'pctUnemploy', 'perHoush', 'pctHousOccup', 'persHomeless', 'persEmergShelt', 'nonViolPerPop'])\n",
    "\n",
    "print(crime_data.shape)\n",
    "crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a399db079b5e31c62ece7d2451e8206a",
     "grade": true,
     "grade_id": "reada",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(crime_data.shape,(949, 13))\n",
    "assert_count_equal(crime_data.columns,['pop',\n",
    "            'pctUrban',\n",
    "            'medIncome',\n",
    "            'pct12-29',\n",
    "            'pct65up',\n",
    "            'pctPoverty',\n",
    "            'pctAllDivorc',\n",
    "            'pctUnemploy',\n",
    "            'perHoush',\n",
    "            'pctHousOccup',\n",
    "            'persHomeless',\n",
    "            'persEmergShelt',\n",
    "            'nonViolPerPop'\n",
    "           ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7FyKPnPepnT9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcce91e220b87b045fc836c84f4eb917",
     "grade": false,
     "grade_id": "cell-793ac60698061e82",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 1b:\n",
    "We want to predict the number of crimes. Identify the features X and the target variable Y, and turn the X and Y DataFrames into Numpy arrays.\n",
    "\n",
    "Make sure `Y` is of shape `(949, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "_FzIEG5DdZo-",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77a539deddec828c3cbb7a7d88a385cb",
     "grade": false,
     "grade_id": "cell-8eb698d0c3f532fd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = crime_data[['pop', 'pctUrban', 'medIncome', 'pct12-29', 'pct65up', 'pctPoverty', 'pctAllDivorc', 'pctUnemploy', 'perHoush', 'pctHousOccup', 'persHomeless', 'persEmergShelt']].values\n",
    "Y = crime_data['nonViolPerPop'].values.reshape(-1,1).astype(float)\n",
    "\n",
    "#WRITE YOUR CODE HERE\n",
    "print(X.shape,Y.shape)\n",
    "print(X[:3])\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b89d5d4a7671055c4129cc89ec4cf29f",
     "grade": true,
     "grade_id": "p1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(X, np.ndarray)\n",
    "assert isinstance(y, np.ndarray)\n",
    "assert_equal(X.shape,(949, 12))\n",
    "assert_equal(Y.shape,(949, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "P9YvTy9kdZpG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14b7a8e66d6dfe628a1f4af1188fb10b",
     "grade": false,
     "grade_id": "cell-afc0b6593e782894",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Split the data into a training set and a test set \n",
    "### Question 2:\n",
    "Split the data into a training and a test set, using teh appropriate sklearn function. Use a  70%-30% split.  \n",
    "Print the number of examples in the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "e_oiLoaWdZpH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa64a075ae6ed557673397513a9eb88f",
     "grade": false,
     "grade_id": "cell-cb09606197bd3f58",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "\n",
    "for M in [X_train, X_test, Y_train, Y_test]:\n",
    "    print(M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25187bc812c9abaa37fdacc398a36311",
     "grade": true,
     "grade_id": "p2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_train.shape== (664, 12)\n",
    "assert Y_test.shape== (285,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZIYFfQN0dZpM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d6a6ad9339a5433eab73ac7abf6cc7c",
     "grade": false,
     "grade_id": "cell-473a187a1ce777d3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Part 3: Knn Regression [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out what this means, and what does it mean when taking the sum?\n",
    "crime_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output of crime_data.isna().sum() is a Series object with the count of missing values in each column of crime_data. \n",
    "# This can help to identify which columns have missing data and how much data is missing in each column, \n",
    "# which is useful for cleaning and preprocessing the data before analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(X_test)#.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(X_test[:,0])#.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pakt de rijen\n",
    "np.isnan(X_test).sum(axis=0), np.isnan(X_train).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pakt de columns\n",
    "np.isnan(X_test).sum(axis=1), np.isnan(X_train).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "prbPvQZodZpN",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52fddad4e8b02fa636554b311c0664cb",
     "grade": false,
     "grade_id": "cell-5db55cc890570964",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Missing Data**: Often the data you are considering is incomplete. For example in some city, the number of homeless people might be unknown. In this case, if you look into the datasets you will find the value *NaN*. This is not a real value, hence Linear Regression cannot handle it.\n",
    "\n",
    "The question is how can we handle missing data. There are many ways to do so, some more sophisticated than others. Here we will use a simple approach. This simple approach fills in the missing values, i.e. replaces the *NaN* by the median of the corresponding feature. E.g. if there is a *NaN* value for the population in one city, this *NaN* value will be replaced by the median number of the population in all other cities in the data.\n",
    "\n",
    "1. figure out what this code  `np.isnan(X_test).sum(axis=0), np.isnan(X_train).sum(axis=0) `    is doing. Remove the `axis=0`, and replace it by `axis=1`. You get it?\n",
    "2. What is the median of the values in the first column of `X_test`?  (variable `v2`)\n",
    "    * Why does `np.median` not work ;-) You are close though! \n",
    "3. Create the first column of X_test in which you replaced all nan values by the median of the first column. (variable `v3`)\n",
    "5. Then do this for all columns at once   using Scikit learn's `SimpleImputer`.\n",
    "    * So the new `X_train` and `X_test` have no more missing values.\n",
    "6. Check that you get exactly the same result using your own method and sklearn's.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f3a8827ebedc7699b1f716a131c2af2",
     "grade": false,
     "grade_id": "p3a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "v2= X_test[:, 0] # replace with your answer\n",
    "v2= median_v2 = np.median(v2[np.isfinite(v2)])\n",
    "v3= np.where(np.isnan(X_test[:, 0]), np.nanmedian(X_test[:, 0][np.isfinite(X_test[:, 0])]), X_test[:, 0])\n",
    "\n",
    "print(v2)\n",
    "print(v3[:10])\n",
    "print(np.isnan(v3).sum())\n",
    "# naize test\n",
    "# all places in v3 which were nan in  X_test[:,0] are now equal to v2\n",
    "print(v3[np.isnan(X_test[:,0])]==v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb12fdffbeb452154399a8f9b7c1e611",
     "grade": true,
     "grade_id": "p3t",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(v2,np.float) \n",
    "assert np.isnan(v3).sum()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "DZEv4VfCdZpP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f45985564dff665156b3a22017c3607a",
     "grade": false,
     "grade_id": "cell-0777a154778f1fe3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Fill in the missing data in the dataset (i.e. replace NaN values in both X_train and X_test) \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "print(np.isnan(X_train).sum())\n",
    "print(np.isnan(X_test).sum())\n",
    "print(X_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "073c3a15bbee7865874bd690781b0a00",
     "grade": true,
     "grade_id": "p3tt",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(np.isnan(X_train).sum(),0)\n",
    "assert_equal(np.isnan(X_test).sum(),0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that you get exactly the same result using your own method and sklearn's.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdf76e360b282d29596f2e5ac46aaa11",
     "grade": true,
     "grade_id": "check",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38b76197c5b46d846914527a5c510406",
     "grade": false,
     "grade_id": "knn",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# KNN\n",
    "\n",
    "Make now the KNN regression algorithm from scratch.\n",
    "\n",
    "* use euclidean again \n",
    "* use `np.argsort` and `[:k]` to find the indexes of the k nearest neighbor rows\n",
    "* use so called *fancy indexing* on numpy array \n",
    "    * `X_train[[2,5,3]]` gives the 2D array with the 2nd, 5th and 3rd row of `X_train`.\n",
    "\n",
    "\n",
    "## Evaluate with RMSE (root mean square error)\n",
    "\n",
    "1. Program the formula for RMSE from scratch \n",
    "2. Compute `Y_predicted`\n",
    "3. Compute the RMSE for the kNN algorithm on this dataset.\n",
    "\n",
    "## Do the same for $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63e4f8ae0510c29ba830d74056beaf8b",
     "grade": true,
     "grade_id": "knna",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def  knn(ExamplesX,ExamplesY,instance,k=5):\n",
    "    \n",
    "    distances = np.sqrt(np.sum((ExamplesX - instance)**2, axis=1))\n",
    "\n",
    "    # Dichtste K pakken\n",
    "    nearest_indices = np.argsort(distances)[:k]\n",
    "    nearest_y = ExamplesY[nearest_indices]\n",
    "    \n",
    "    # Bereken de mean van de y values\n",
    "    y_pred = nearest_y.mean()\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "knn(X_train,Y_train,X_test[0,:]), Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "190680a65e316cd45d86a9de00fdefcf",
     "grade": false,
     "grade_id": "rmse",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def rmse(u,v): ## u, v are 1D arrays of the same length\n",
    "    return (sum((u[i]-v[i])**2 for i in range(len(u)))/len(u))**0.5\n",
    "rmse([2,3,5,6,7,34],[2,3,5,6,7,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f3d13fa820f4376dfb6452f6d49f57b",
     "grade": false,
     "grade_id": "rsquare",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def rsquare(predicted,true): ## u, v are 1D arrays of the same length\n",
    "    return 1- (sum(np.array(true)-np.array(predicted))**2)/ (sum((true- np.mean(true))**2))\n",
    "rsquare([2,3,5,6,7,34],[2,3,5,6,7,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "229cde3a51a5e470df6afd06b6f710fc",
     "grade": true,
     "grade_id": "knneval",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "Y_predicted = rmse(([knn(X_train,Y_train,i) for i in X_test]), Y_test)\n",
    "Square = rsquare(knn(X_train,Y_train,i), Y_test)\n",
    "print(Y_predicted, Square)\n",
    "\n",
    "Y_predicted.shape,RMSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ba78569e3bb8f2422dbcb6ab4d4cd84",
     "grade": false,
     "grade_id": "testb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# What is happening here?\n",
    "\n",
    "* Explain what we are doing in the next cell.\n",
    "* Is this according to your intuition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh.fit(X_train, Y_train)\n",
    "\n",
    "Y_predicted2= neigh.predict(X_test )\n",
    "\n",
    "rmse(Y_predicted2,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d1ca72ff085ab72c8951c792d8f8f29",
     "grade": true,
     "grade_id": "test2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "We berekenen de KNN op basis van 5 neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2644c2cf1e7224dab94d89ec534a4f6f",
     "grade": false,
     "grade_id": "norm",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Normalization\n",
    "\n",
    "\n",
    "## Z- transformation\n",
    "\n",
    "* We transform the data such that each kolom has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "## Unit normalization\n",
    "\n",
    "* We transform the data such that each row has unit norm.\n",
    "* A unit normn of a vector $v$ means that its length equals 1, that is $\\sqrt{v\\cdot v}$ equals 1, where $v\\cdot v$ is the dot product of $v$ with itself, that is $\\Sigma_i v_i\\cdot v_i$.\n",
    "\n",
    "\n",
    "## Your task\n",
    "\n",
    "* Implement both normalisations of a matrix and **make tests to check that they work correctly**.\n",
    "    * Check out `np.linalg.norm?`\n",
    "    * Tests are real computer tests. Not a print that you then check with your eyes.\n",
    "    * So use `assert` statements, or make a test which returns True.\n",
    "    * Of course you may add a useful print. \n",
    "* Do not use predefined functions for these normalisations, but program them from the here given definitions.\n",
    "* Finally check that they give the same results as the [scikit learn normalizer](https://scikit-learn.org/stable/modules/preprocessing.html#normalization) and [standardizer](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4559dfcb0f478f9587b3405ae98ceb8d",
     "grade": false,
     "grade_id": "norma",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Assume M is a np.array\n",
    "def standardize(M):\n",
    "    #WRITE YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    \n",
    "def normalize(X):\n",
    "    #WRITE YOUR CODE HERE\n",
    "    \n",
    "X = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                   [ 0.,  1., -1.]])  \n",
    "\n",
    "print(standardize(X))\n",
    "\n",
    "\n",
    "normalize(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75e3b3cb9e22cdb2f0606c9e307207ab",
     "grade": false,
     "grade_id": "normc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Here in the answer cell below:\n",
    "\n",
    "* your own tests\n",
    "*  tests that scikit learn functions do the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f624bdba3eb3f8eba6a99ff18a1232d",
     "grade": true,
     "grade_id": "norma1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e70f68788ae8b60a40a4e4c36c2fcc9",
     "grade": true,
     "grade_id": "normt",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(X.shape, normalize(X).shape)\n",
    "assert_equal(X.shape, standardize(X).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TJIk0ppWpnUV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cf5c1b96c99fb45335b32e5d095cb3e",
     "grade": false,
     "grade_id": "cell-5f6424ae3678e3c9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3\n",
    " \n",
    " \n",
    "* Do the KNN regression again but now on the normalized data.\n",
    "* Conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "BQc0v7GCdZpV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a7ea5b2db20746db0e405409c584c7b",
     "grade": true,
     "grade_id": "cell-40087f3cfc1918c7",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a6b9e72cc2b6f4706c1ab7af66e5156",
     "grade": false,
     "grade_id": "imp",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Improving KNN\n",
    "\n",
    "With KNN each neighbour is equal, as we take the mean or the majority class. Now, we may change KNN by *weighing* the imprtance of the neighbors, for instance with the distance or similarity. \n",
    "\n",
    "Implement that improvement:\n",
    "\n",
    "* find an easy way to create weights from distances.\n",
    "* normalize these weighjts so that the weights of all neighbours add up to 1.\n",
    "* find out the wonderfullness of the *dot product*, see how you take the dot product of 2 numpy arrays, and, well, use it to compute the weighted mean, basically by saying *weights times values*. \n",
    "\n",
    "* Work it out using the tips dataset for which you predict the tip from the total bill.\n",
    "* Do all steps we do in an ML project and predict the tip using KNN regression with weighted neighbors.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d56cd9b30778dee679b53b68f647f331",
     "grade": false,
     "grade_id": "tips",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "print(tips.shape)\n",
    "sns.regplot(x='total_bill', y='tip', data=tips);\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b3433b895657bfef19543a09d5139f0",
     "grade": false,
     "grade_id": "mf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Male vs Female\n",
    "\n",
    "We  wonder if males tip differently than females. We first investigate visually. Then we compute.\n",
    "\n",
    "1. Add `hue='sex'` to the `sns.scatterplot` command. \n",
    "2. Simply plot two regplots on top of each other, one for the males, one for the females.\n",
    "   * Of course you use Boolean indexing to restrict `data` to the required sex.\n",
    "3. Read up what those shaded areas in the `regplot` mean. Can you draw a conclusion about male vs female tipping?\n",
    "4. Finally run your weighted KNN and a scikit learn linear regression, and plot the regression line, the true values and the KNN-predicted tips for the test-set. Can you conclude something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d326fdefd47d967724c6dc6ddb493576",
     "grade": true,
     "grade_id": "mfa",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='total_bill', y='tip', data=tips, hue ='sex')\n",
    "sns.regplot(x='total_bill', y='tip', data=tips[tips['sex'] == 'Female']);\n",
    "sns.regplot(x='total_bill', y='tip', data=tips[tips['sex'] == 'Male']);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mvRc3NfNpnX_",
    "jEVT2ICapnYY",
    "9VnA1f6gpnZF",
    "r0tPQjwcpnZq",
    "ToGW3LxdpnZy",
    "xtQdj-BJpnaK",
    "23xaVneOdZrC"
   ],
   "name": "Practical Assignment 1 - 2021 Answer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
